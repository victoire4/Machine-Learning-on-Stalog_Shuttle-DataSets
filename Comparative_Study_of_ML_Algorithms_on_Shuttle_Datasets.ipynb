{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mathematical operation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For draw graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# For time spend on the operation\n",
    "import time\n",
    "# For training models using sciket.learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of training data\n",
    "data_train=pd.read_csv('/media/mydata/PHD Opportunity/WORK/data_train.csv',header=None,sep=\" \")\n",
    "# Import of testing data\n",
    "data_test=pd.read_csv('/media/mydata/PHD Opportunity/WORK/data_test.csv',header=None,sep=\" \")\n",
    "# Merge both above data: in fact, we transpose first the two data. Then, we concatenate the training and testing sets \n",
    "df=pd.concat([data_train.T,data_test.T],axis=1)\n",
    "# We uniformly number the columns\n",
    "df.columns=[i for i in range(58000)]\n",
    "# We transpose again the data\n",
    "data=df.T\n",
    "#Data display\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.1 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Input visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Scatter plot of feature #############\n",
    "\n",
    "# Dataset with only attributes\n",
    "df1=data.drop(9,axis=1)\n",
    "# Define ficgure and it size\n",
    "plt.figure(figsize=(20,12))\n",
    "# Define value for x axis\n",
    "x=[i for i in range(58000)]\n",
    "# Use \"for\" loop to plot all the nine (09) scatter plot\n",
    "for i in range(9): \n",
    "# Define the dataframe for each feature\n",
    "    df2=df1[i]\n",
    "# For 9 plots, we use subplot with 3 lines and 3 columns\n",
    "    plt.subplot(3,3,i+1)\n",
    "# Generate scatter plot for each feature\n",
    "    sns.scatterplot(x,df2)\n",
    "# x label of each plot\n",
    "    plt.xlabel('column'+str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Output visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Barchart plot of label #############\n",
    "\n",
    "# Define ficgure and it size\n",
    "plt.figure(figsize=(20,7))\n",
    "# For 3 plots, we use subplot with 1 line and 3 columns\n",
    "plt.subplot(1,3,1)\n",
    "# Barchart of dataset with only label for all dataset\n",
    "sns.countplot(data[9])\n",
    "plt.title(\"All dataset\")\n",
    "plt.xlabel(\"Label classes\")\n",
    "plt.subplot(1,3,2)\n",
    "# Barchart of dataset with only label for training set\n",
    "sns.countplot(data_train[9])\n",
    "plt.title(\"Training set\")\n",
    "plt.xlabel(\"Label classes\")\n",
    "plt.subplot(1,3,3)\n",
    "# Barchart of dataset with only label for testing set\n",
    "sns.countplot(data_test[9])\n",
    "plt.title(\"Testing set\")\n",
    "plt.xlabel(\"Label classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Desciptive statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Design prediction methods using Logisic regression (LR), KNN, SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Shuffle of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Shuffle of data 10 times and put in the dictionnary ####\n",
    "dict={}\n",
    "for i in range(10):\n",
    "   data=data.sample(frac=1).reset_index(drop=True)\n",
    "   dict[\"sample\"+str(i)]=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Normalization of each dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### We normalize all the dataframe and define the training data and testing data #######\n",
    "\n",
    "# Create empty list\n",
    "lst_xtr=[]  # For inputs training data\n",
    "lst_xte=[]  # For inputs testing data\n",
    "lst_ytr=[]  # For outputs training data\n",
    "lst_yte=[]  # For outputs testing data\n",
    "for i in range(10):\n",
    "    data=dict[\"sample\"+str(i)]\n",
    "# Define the inputs data   \n",
    "    X=data.drop(9,axis=1)\n",
    "# Define the output data\n",
    "    Y=data[9]\n",
    "# Apply \"test plit\" for define the inputs training and testing sets, and output training and testing sets\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25)\n",
    "# Apply normalization method to inputs training and testing set\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "# New inputs training set\n",
    "    X_train1=scaler.transform(X_train)\n",
    "    scaler.fit(X_test)\n",
    "# New inputs testing set\n",
    "    X_test1=scaler.transform(X_test)\n",
    "# Append all those dataset in the list respectively\n",
    "    lst_xtr.append(X_train1)\n",
    "    lst_xte.append(X_test1)\n",
    "    lst_ytr.append(Y_train)\n",
    "    lst_yte.append(Y_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list\n",
    "lst_acc_tr_lr=[]  # List for training accuracies\n",
    "lst_acc_te_lr=[]  # List for testing accuracies\n",
    "lst_time_tr_lr=[] # List for training time\n",
    "lst_time_te_lr=[] # List for testing time\n",
    "# Hyper parameter optimization using Grid search\n",
    "parameters={'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']} # set of parameters\n",
    "l = LogisticRegression(random_state = 40,multi_class=\"auto\") # Define the LR algorithm\n",
    "lr=GridSearchCV(l,param_grid=parameters) # Apply GridSearch\n",
    "# Apply \"for\" loop for computation of all the accuracies and time\n",
    "for i in range(10):\n",
    "    start1 = time.time() # Start time for training\n",
    "    lr.fit(lst_xtr[i], lst_ytr[i]) # Model training \n",
    "    Y_train_predict=lr.predict(lst_xtr[i]) # Training data prediction\n",
    "    stop1 = time.time() # Stop time for training\n",
    "    start2 = time.time() # Start time for testing\n",
    "    Y_test_predict=lr.predict(lst_xte[i]) # Testing data prediction  \n",
    "    stop2 = time.time() # Stop time for testing\n",
    "# Complet the lists\n",
    "    lst_acc_tr_lr.append(accuracy_score(lst_ytr[i],Y_train_predict))\n",
    "    lst_acc_te_lr.append(accuracy_score(lst_yte[i],Y_test_predict))\n",
    "    lst_time_tr_lr.append(stop1 - start1) # Training time\n",
    "    lst_time_te_lr.append(stop2 - start2) # Test time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_acc_tr_knn=[]\n",
    "lst_acc_te_knn=[]\n",
    "lst_time_tr_knn=[]\n",
    "lst_time_te_knn=[]\n",
    "parameters={'n_jobs':[None,-1],'n_neighbors':[5,6,7],'p':[1,2]}\n",
    "KNN0=KNeighborsClassifier(algorithm='auto', weights='distance') # Define the KNN algorithm\n",
    "KNN=GridSearchCV(KNN0,param_grid=parameters)\n",
    "for i in range(10):\n",
    "    start1 = time.time()\n",
    "    KNN.fit(lst_xtr[i], lst_ytr[i])\n",
    "    Y_train_predict=KNN.predict(lst_xtr[i])\n",
    "    stop1 = time.time()\n",
    "    start2 = time.time()\n",
    "    Y_test_predict=KNN.predict(lst_xte[i])\n",
    "    stop2 = time.time()\n",
    "    lst_acc_tr_knn.append(accuracy_score(lst_ytr[i],Y_train_predict))\n",
    "    lst_acc_te_knn.append(accuracy_score(lst_yte[i],Y_test_predict))\n",
    "    lst_time_tr_knn.append(stop1 - start1)\n",
    "    lst_time_te_knn.append(stop2 - start2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_acc_tr_svm=[]\n",
    "lst_acc_te_svm=[]\n",
    "lst_time_tr_svm=[]\n",
    "lst_time_te_svm=[]\n",
    "parameters={'C':[1,2,3,4],'gamma':[\"auto\",\"scale\"]}\n",
    "svc0 = SVC(kernel='rbf')                             # Define the SVM algorithm\n",
    "svc=GridSearchCV(svc0,param_grid=parameters)\n",
    "for i in range(10):\n",
    "    start1 = time.time()\n",
    "    svc.fit(lst_xtr[i], lst_ytr[i])\n",
    "    Y_train_predict=svc.predict(lst_xtr[i])\n",
    "    stop1 = time.time()\n",
    "    start2 = time.time()\n",
    "    Y_test_predict=svc.predict(lst_xte[i])\n",
    "    stop2 = time.time()\n",
    "    lst_acc_tr_svm.append(accuracy_score(lst_ytr[i],Y_train_predict))\n",
    "    lst_acc_te_svm.append(accuracy_score(lst_yte[i],Y_test_predict))\n",
    "    lst_time_tr_svm.append(stop1 - start1)\n",
    "    lst_time_te_svm.append(stop2 - start2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Comparison of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 In term of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Mean accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Print the mean accuracy of each model ########\n",
    "\n",
    "print(\"Mean acuracy LR: \",np.mean(lst_acc_te_lr))\n",
    "print(\"Mean acuracy KNN: \",np.mean(lst_acc_te_knn))\n",
    "print(\"Mean acuracy SVM: \",np.mean(lst_acc_te_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Box-plot of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Build the dataset to all the accuracies of each model ############\n",
    "\n",
    "Scores=[lst_acc_te_lr,lst_acc_te_knn,lst_acc_te_svm]\n",
    "Names=[\"LR\",\"KNN\",\"SVM\"]\n",
    "df1=pd.DataFrame(Scores)\n",
    "df2=df1.T\n",
    "df2.columns=Names\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Box-plot ############\n",
    "\n",
    "Scores=[lst_acc_te_lr,lst_acc_te_knn,lst_acc_te_svm]\n",
    "Names=[\"LR\",\"KNN\",\"SVM\"]\n",
    "df1=pd.DataFrame(Scores)\n",
    "df2=df1.T\n",
    "df2.columns=Names\n",
    "plt.figure(figsize=(8,9))\n",
    "plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15)\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.boxplot(data=df2, width=0.8,saturation=50,palette=[\"white\",\"white\",\"white\"],medianprops={'color':'red'},showmeans=True)\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.xlabel('Model', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Mean training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Training time LR: \",np.mean(lst_time_tr_lr),\"s\")\n",
    "print(\"Mean Training time KNN: \",np.mean(lst_time_tr_knn),\"s\")\n",
    "print(\"Mean Training time SVM: \",np.mean(lst_time_tr_svm),\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Box-plot to training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores=[lst_time_tr_lr,lst_time_tr_knn,lst_time_tr_svm]\n",
    "Names_r=[\"LR\",\"KNN\",\"SVM\"]\n",
    "df1=pd.DataFrame(Scores)\n",
    "df2=df1.T\n",
    "df2.columns=Names_r\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15)\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.boxplot(data=df2, width=0.8,saturation=50,palette=[\"white\",\"white\",\"white\"],medianprops={'color':'red'},showmeans=True)\n",
    "plt.ylabel('Training time (s)', fontsize=18)\n",
    "plt.xlabel('Models', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Testing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Mean testing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Training time LR: \",np.mean(lst_time_te_lr),\"s\")\n",
    "print(\"Mean Training time KNN: \",np.mean(lst_time_te_knn),\"s\")\n",
    "print(\"Mean Training time SVM: \",np.mean(lst_time_te_svm),\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Box-plot to testing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores=[lst_time_te_lr,lst_time_te_knn,lst_time_te_svm]\n",
    "Names_r=[\"LR\",\"KNN\",\"SVM\"]\n",
    "df1=pd.DataFrame(Scores)\n",
    "df2=df1.T\n",
    "df2.columns=Names_r\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=15)\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.boxplot(data=df2, width=0.8,saturation=50,palette=[\"white\",\"white\",\"white\"],medianprops={'color':'red'},showmeans=True)\n",
    "plt.ylabel('Testing time (s)', fontsize=18)\n",
    "plt.xlabel('Models', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Result for resampling dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Define the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = SMOTE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('/media/mydata/PHD Opportunity/WORK/data_train.csv',header=None,sep=\" \")\n",
    "data_test=pd.read_csv('/media/mydata/PHD Opportunity/WORK/data_test.csv',header=None,sep=\" \")\n",
    "df=pd.concat([data_train.T,data_test.T],axis=1)\n",
    "df.columns=[i for i in range(58000)]\n",
    "df11=df.T\n",
    "df11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Define the features set and the label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df11.drop(9,axis=1)\n",
    "Y=df11[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Apply the method to oversampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,Y1=method.fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Plot the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Divide the data to training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X1,Y1,test_size=0.25)   \n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train1=scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test1=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "l = LogisticRegression(random_state = 40,multi_class=\"auto\")\n",
    "lr=GridSearchCV(l,param_grid=parameters)\n",
    "start1 = time.time()\n",
    "lr.fit(X_train1, Y_train)\n",
    "Y_train_predict=lr.predict(X_train1)\n",
    "stop1 = time.time()\n",
    "start2 = time.time()\n",
    "Y_test_predict=lr.predict(X_test1)\n",
    "stop2 = time.time()\n",
    "print('Training:')\n",
    "print(accuracy_score(Y_train,Y_train_predict))\n",
    "print('Test:')\n",
    "print(accuracy_score(Y_test,Y_test_predict))\n",
    "print(f\"Training time: {stop1 - start1}s\")\n",
    "print(f\"Test time: {stop2 - start2}s\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=Y_test, y_pred=Y_test_predict)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'n_jobs':[None,-1],'n_neighbors':[5,6,7],'p':[1,2]}\n",
    "KNN0=KNeighborsClassifier(algorithm='auto', weights='distance')\n",
    "KNN=GridSearchCV(KNN0,param_grid=parameters)\n",
    "start1 = time.time()\n",
    "KNN.fit(X_train1, Y_train)\n",
    "Y_train_predict=KNN.predict(X_train1)\n",
    "stop1 = time.time()\n",
    "start2 = time.time()\n",
    "Y_test_predict=KNN.predict(X_test1)\n",
    "stop2 = time.time()\n",
    "print('Training:')\n",
    "print(accuracy_score(Y_train,Y_train_predict))\n",
    "print('Test:')\n",
    "print(accuracy_score(Y_test,Y_test_predict))\n",
    "print(f\"Training time: {stop1 - start1}s\")\n",
    "print(f\"Test time: {stop2 - start2}s\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=Y_test, y_pred=Y_test_predict)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'C':[1,2,3,4],'gamma':[\"auto\",\"scale\"]}\n",
    "svc0 = SVC(kernel='rbf')\n",
    "svc=GridSearchCV(svc0,param_grid=parameters)\n",
    "start1 = time.time()\n",
    "svc.fit(X_train1, Y_train)\n",
    "Y_train_predict=svc.predict(X_train1)\n",
    "stop1 = time.time()\n",
    "start2 = time.time()\n",
    "Y_test_predict=svc.predict(X_test1)\n",
    "stop2 = time.time()\n",
    "print('Training:')\n",
    "print(accuracy_score(Y_train,Y_train_predict))\n",
    "print('Test:')\n",
    "print(accuracy_score(Y_test,Y_test_predict))\n",
    "print(f\"Training time: {stop1 - start1}s\")\n",
    "print(f\"Test time: {stop2 - start2}s\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_true=Y_test, y_pred=Y_test_predict)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
